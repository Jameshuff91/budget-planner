name: Test

on:
  push:
    branches: [master, main, develop]
  pull_request:
    branches: [master, main, develop]

env:
  NODE_ENV: test

jobs:
  # Unit and Integration Tests
  unit-tests:
    name: Unit Tests (Node ${{ matrix.node-version }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        node-version: [18, 20]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: ${{ runner.os }}-node-${{ matrix.node-version }}-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-${{ matrix.node-version }}-
            ${{ runner.os }}-node-
            ${{ runner.os }}-

      - name: Install dependencies
        run: npm ci

      - name: Run unit tests with coverage
        run: npm test -- --coverage --reporter=json --reporter=html --reporter=text

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        with:
          name: coverage-node-${{ matrix.node-version }}
          path: coverage/
          retention-days: 7

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          flags: unittests
          name: unit-tests-node-${{ matrix.node-version }}
          fail_ci_if_error: false

  # E2E Tests
  e2e-tests:
    name: E2E Tests (${{ matrix.browser }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        browser: [chromium, firefox, webkit]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: ${{ runner.os }}-node-20-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-20-
            ${{ runner.os }}-node-
            ${{ runner.os }}-

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright Browsers
        run: npx playwright install --with-deps ${{ matrix.browser }}

      - name: Build application
        run: npm run build

      - name: Run Playwright tests
        run: npx playwright test --project=${{ matrix.browser }} --reporter=json,html
        env:
          CI: true

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report-${{ matrix.browser }}
          path: playwright-report/
          retention-days: 7

      - name: Upload test videos
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-videos-${{ matrix.browser }}
          path: test-results/
          retention-days: 7

  # Code Quality Checks
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: ${{ runner.os }}-node-20-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-20-
            ${{ runner.os }}-node-
            ${{ runner.os }}-

      - name: Install dependencies
        run: npm ci

      - name: Check TypeScript types
        run: npm run type-check

      - name: Run ESLint
        run: npm run lint -- --max-warnings 0
        continue-on-error: true # Since ESLint is set to warnings

      - name: Check code formatting
        run: npm run format -- --check

      - name: Check bundle size
        run: |
          npm run build
          echo "### Bundle Size Report" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          du -sh .next/static/chunks/*.js | sort -h >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

  # Performance Budget Check
  performance-budget:
    name: Performance Budget
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build

      - name: Check bundle sizes
        run: |
          # Define performance budgets (in KB)
          MAX_JS_SIZE=500
          MAX_CSS_SIZE=100

          # Check JavaScript bundle size
          JS_SIZE=$(find .next/static/chunks -name "*.js" -exec du -k {} + | awk '{sum+=$1} END {print sum}')
          echo "JavaScript bundle size: ${JS_SIZE}KB (budget: ${MAX_JS_SIZE}KB)"

          # Check CSS bundle size  
          CSS_SIZE=$(find .next/static/css -name "*.css" -exec du -k {} + 2>/dev/null | awk '{sum+=$1} END {print sum}' || echo 0)
          echo "CSS bundle size: ${CSS_SIZE}KB (budget: ${MAX_CSS_SIZE}KB)"

          # Fail if over budget
          if [ "$JS_SIZE" -gt "$MAX_JS_SIZE" ]; then
            echo "❌ JavaScript bundle exceeds budget!"
            exit 1
          fi

          if [ "$CSS_SIZE" -gt "$MAX_CSS_SIZE" ]; then
            echo "❌ CSS bundle exceeds budget!"
            exit 1
          fi

          echo "✅ All bundles within budget!"

  # Test Result Summary
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, e2e-tests, code-quality, performance-budget]
    if: always()

    steps:
      - name: Check test results
        run: |
          echo "### Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Check each job status
          if [ "${{ needs.unit-tests.result }}" == "success" ]; then
            echo "✅ Unit Tests: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Unit Tests: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.e2e-tests.result }}" == "success" ]; then
            echo "✅ E2E Tests: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ E2E Tests: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.code-quality.result }}" == "success" ]; then
            echo "✅ Code Quality: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Code Quality: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.performance-budget.result }}" == "success" ]; then
            echo "✅ Performance Budget: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Performance Budget: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          # Overall status
          if [ "${{ needs.unit-tests.result }}" == "success" ] && \
             [ "${{ needs.e2e-tests.result }}" == "success" ] && \
             [ "${{ needs.code-quality.result }}" == "success" ] && \
             [ "${{ needs.performance-budget.result }}" == "success" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ✅ All tests passed!" >> $GITHUB_STEP_SUMMARY
            exit 0
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ❌ Some tests failed!" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
